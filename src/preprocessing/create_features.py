"""
Script t·∫°o FEATURES (KH√îNG normalize, KH√îNG t·∫°o sequences)
Tu·∫ßn 3 - Th·ª© 4

Input: *_clean.csv
Output: *_features.csv (RAW features - ch∆∞a normalize)

L∆∞u √Ω: KH√îNG t·∫°o .pkl v√† .npz ·ªü ƒë√¢y!
"""

from __future__ import annotations

import pandas as pd
import numpy as np
from pathlib import Path
import sys

project_root = Path(__file__).resolve().parent.parent.parent
sys.path.append(str(project_root))

from src.utils.config import config
from src.preprocessing.technical_indicators import TechnicalIndicators


def create_all_features(df: pd.DataFrame, dataset_name: str) -> pd.DataFrame:
    """
    T·∫°o T·∫§T C·∫¢ features (CH∆ØA normalize)
    
    Features:
    - RSI(14)
    - MA7, MA25
    - Price change %
    - Volume change %
    - High-Low range %
    
    Args:
        df: DataFrame g·ªëc (clean)
        dataset_name: T√™n dataset
    
    Returns:
        DataFrame v·ªõi RAW features (ch∆∞a normalize)
    """
    print(f"\n{'='*60}")
    print(f"üîß T·∫†O FEATURES: {dataset_name}")
    print(f"{'='*60}")
    
    required = {"datetime", "open", "high", "low", "close", "volume"}
    missing = required - set(df.columns)
    if missing:
        raise ValueError(f"Thi·∫øu c·ªôt: {sorted(missing)}")

    df_features = df.copy()
    
    # 1. RSI (14)
    print("[1/5] T√≠nh RSI(14)...")
    df_features = TechnicalIndicators.add_rsi(df_features, period=14, column='close')
    
    # 2. MA (7, 25)
    print("[2/5] T√≠nh MA7, MA25...")
    df_features = TechnicalIndicators.add_moving_averages(df_features, periods=[7, 25], column='close')
    
    # 3. Price Change %
    print("[3/5] T√≠nh Price Change %...")
    df_features['price_change_pct'] = df_features['close'].pct_change() * 100
    
    # 4. Volume Change %
    print("[4/5] T√≠nh Volume Change %...")
    df_features['volume_change_pct'] = df_features['volume'].pct_change() * 100
    df_features['volume_change_pct'].replace([np.inf, -np.inf], np.nan, inplace=True)
    
    # 5. High-Low Range %
    print("[5/5] T√≠nh High-Low Range %...")
    df_features['hl_range_pct'] = ((df_features['high'] - df_features['low']) / df_features['close'].replace(0, np.nan)) * 100
    
    # X·ª≠ l√Ω NaN
    print(f"\n‚ö†Ô∏è  X·ª≠ l√Ω NaN:")
    nan_cols = ['RSI_14', 'MA_7', 'MA_25', 'price_change_pct', 'volume_change_pct', 'hl_range_pct']
    for col in nan_cols:
        nan_count = df_features[col].isna().sum()
        if nan_count > 0:
            print(f"  ‚Ä¢ {col}: {nan_count} NaN")
    
    # Forward fill + drop
    df_features.fillna(method='ffill', inplace=True)
    rows_before = len(df_features)
    df_features.dropna(inplace=True)
    rows_after = len(df_features)
    
    if rows_before != rows_after:
        print(f"\n‚úÇÔ∏è  ƒê√£ drop {rows_before - rows_after} d√≤ng ƒë·∫ßu c√≥ NaN")
    
    print(f"\n‚úÖ Ho√†n th√†nh!")
    print(f"  ‚Ä¢ S·ªë d√≤ng: {len(df_features):,}")
    print(f"  ‚Ä¢ S·ªë c·ªôt: {len(df_features.columns)}")
    print(f"  ‚Ä¢ Columns: {list(df_features.columns)}")
    
    return df_features


def select_features_for_model(df: pd.DataFrame, timeframe: str) -> pd.DataFrame:
    """
    Ch·ªçn features ph√π h·ª£p d·ª±a tr√™n khung th·ªùi gian
    
    - 5m: B·ªè MA_25, open (t∆∞∆°ng quan cao)
    - 1d: B·ªè open, gi·ªØ MA_7, MA_25
    """
    print(f"\n{'='*60}")
    print(f"üìã CH·ªåN FEATURES CHO KHUNG {timeframe.upper()}")
    print(f"{'='*60}")
    
    if timeframe == '5m':
        selected = [
            'datetime',
            'close', 'high', 'low', 'volume',  # B·ªè open
            'MA_7',  # B·ªè MA_25
            'RSI_14', 'price_change_pct', 'volume_change_pct', 'hl_range_pct'
        ]
        print(f"  ‚Ä¢ B·ªè: open (correlation cao v·ªõi close), MA_25")
        print(f"  ‚Ä¢ S·ªë features: {len(selected) - 1} (9 features)")  # Tr·ª´ datetime
    else:  # '1d'
        selected = [
            'datetime',
            'close', 'high', 'low', 'volume',  # B·ªè open
            'MA_7', 'MA_25',
            'RSI_14', 'price_change_pct', 'volume_change_pct', 'hl_range_pct'
        ]
        print(f"  ‚Ä¢ B·ªè: open (correlation cao v·ªõi close)")
        print(f"  ‚Ä¢ S·ªë features: {len(selected) - 1} (10 features)")
    
    missing = [c for c in selected if c not in df.columns]
    if missing:
        raise ValueError(f"Thi·∫øu c·ªôt: {missing}")
    
    df_selected = df[selected].copy()
    print(f"\n‚úÖ Features cu·ªëi c√πng: {[c for c in selected if c != 'datetime']}")
    
    return df_selected


def main():
    """Main workflow: Ch·ªâ t·∫°o features, KH√îNG normalize"""
    
    print("\n" + "="*80)
    print("üéØ T·∫†O FEATURES (RAW - CH∆ØA NORMALIZE)")
    print("="*80)
    print("\n‚ö†Ô∏è  L∆ØU √ù:")
    print("  ‚Ä¢ Script n√†y CH·ªà t·∫°o features")
    print("  ‚Ä¢ KH√îNG normalize (ƒë·ªÉ tr√°nh data leakage)")
    print("  ‚Ä¢ KH√îNG t·∫°o sequences (ƒë·ªÉ trong train script)")
    print("  ‚Ä¢ Output: *_features.csv (RAW features)")
    
    processed_dir = Path(config.PROCESSED_DATA_DIR)
    
    datasets = [
        {
            'name': 'BTC 5m',
            'input': 'BTCUSDT_5m_clean.csv',
            'output': 'BTCUSDT_5m_features.csv',
            'timeframe': '5m'
        },
        {
            'name': 'ETH 5m',
            'input': 'ETHUSDT_5m_clean.csv',
            'output': 'ETHUSDT_5m_features.csv',
            'timeframe': '5m'
        },
        {
            'name': 'BTC 1d',
            'input': 'BTCUSDT_1d_clean.csv',
            'output': 'BTCUSDT_1d_features.csv',
            'timeframe': '1d'
        },
        {
            'name': 'ETH 1d',
            'input': 'ETHUSDT_1d_clean.csv',
            'output': 'ETHUSDT_1d_features.csv',
            'timeframe': '1d'
        }
    ]
    
    success_count = 0
    
    for ds in datasets:
        input_path = processed_dir / ds['input']
        
        if not input_path.exists():
            print(f"\n‚ùå Thi·∫øu file: {input_path}")
            continue
        
        # Load d·ªØ li·ªáu
        df = pd.read_csv(input_path)
        df['datetime'] = pd.to_datetime(df['datetime'])
        
        # T·∫°o features
        df_features = create_all_features(df, ds['name'])
        
        # Ch·ªçn features
        df_selected = select_features_for_model(df_features, ds['timeframe'])
        
        # L∆∞u file
        output_path = processed_dir / ds['output']
        df_selected.to_csv(output_path, index=False)
        print(f"\nüíæ ƒê√£ l∆∞u: {output_path.name}")
        print(f"  ‚Ä¢ {len(df_selected):,} d√≤ng")
        print(f"  ‚Ä¢ {len(df_selected.columns)} c·ªôt")
        
        success_count += 1
    
    # T·ªïng k·∫øt
    print("\n" + "="*80)
    print("üìä T·ªîNG K·∫æT")
    print("="*80)
    print(f"‚úÖ Th√†nh c√¥ng: {success_count}/{len(datasets)} datasets")
    
    if success_count == len(datasets):
        print("\n‚úÖ Ho√†n th√†nh Tu·∫ßn 3!")
        print("\nFiles ƒë√£ t·∫°o (RAW features):")
        for ds in datasets:
            print(f"  ‚Ä¢ {ds['output']}")
        
        print("\nüìã Features:")
        print("\n  üîπ Khung 5m (10 features):")
        print("     open, close, high, low, volume,")
        print("     MA_7, RSI_14,")
        print("     price_change_pct, volume_change_pct, hl_range_pct")
        
        print("\n  üîπ Khung 1d (11 features):")
        print("     open, close, high, low, volume,")
        print("     MA_7, MA_25, RSI_14,")
        print("     price_change_pct, volume_change_pct, hl_range_pct")
        
        print("\n" + "="*80)
        print("üöÄ TI·∫æP THEO: TU·∫¶N 4 - TRAINING")
        print("="*80)
        print("Trong train script, b·∫°n s·∫Ω:")
        print("  1. Load *_features.csv")
        print("  2. Chia 70/15/15")
        print("  3. Fit scaler tr√™n TRAIN set")
        print("  4. Transform t·ª´ng split ri√™ng")
        print("  5. T·∫°o sequences")
        print("  6. Train model")


if __name__ == "__main__":
    main()